---
layout: post
title: Comment on Sharding in Ethereum
description: An alternate approach to sharding in Ethereum
---
<a href="https://github.com/ethereum/wiki/wiki/Sharding-FAQ">Vitalik Buterin's FAQ</a> on sharding in Ethereum has inspired me to come up with a more simple, robust, and versatile alternative to sharding. I start by slicing the network horizontally instead of vertically. Instead of creating groups of nodes that are responsible for a subset of the state (shards), I propose to create groups of nodes that are responsible for the full state each. I.e. instead of having 50 shards with 100 nodes each, there would be 100 groups consisting of 50 subnodes each, with each group holding the full state. I call this the *boring variant*. It already allows to scale the network by an order of magnitude or two, but the really magic starts in the *bold variant* that allows these groups to be incomplete and subnodes to mine on their own. Chances are high that I made some mistakes in my thinking, but I would love to find out where they are, so I invite you to comment this approach on <a href="https://www.reddit.com/r/ethereum/">the Ethereum reddit</a>.

*Subnodes*: One of the great advantages of Ethereum in comparison to other cryptocurrencies is that the state is encoded in a <a href="https://blog.ethereum.org/2015/11/15/merkling-in-ethereum/">Merkle tree</a>, and its current root present in every block. This allows to create compact proofs about the current state. In comparison, it is not possible to prove that a given output is unspent in Bitcoin without scanning the whole transaction history since the creation of that output. This valuable property of Ethereum allows the creation of subnodes that are more powerful than normal SPV nodes as they are able to craft valid blocks with valid transactions in them. Subnodes are nodes that are only concerned with a subset of the state, and only download and validate transactions that are relevant to that subset. Whoever runs a subnode is free to specify what subset of the state he is interested in. By default, this can be a random subset, but it might also make sense for a specific users to track the state that is relevant to all the contracts he is involved in. This stands in contrast to Vitalik’s proposal, where nodes are exogenously assigned to a subset of the state (shard). By running such a subnode, a user would be able to monitor all the contracts relevant to him and even prove if something went wrong, i.e. if an invalid state transition was included in the block chain, he could provide the relevant transaction together with the Merkle-verified data before and after the transaction to prove to anyone that the transaction was incorrectly processed. Such a subnode could craft valid blocks that contain valid transactions, at least as long as these transactions only concern the state the node is tracking. This could even be expanded to simple "cross-shard" transactions if the node fetches the relevant data for those transaction from other nodes at O(log n) overhead.

*Block creation, boring variant*: In order to reliably validate old blocks and forge new blocks of transactions, subnodes have an incentive to form groups with other subnodes. Ideally, each group is large enough to cover the full state. Ideally, they also have some “mining power” among themselves, such that they can create new blocks. In the simplest case, such a group of nodes is actually just one supercomputer operated by a powerful miner and corresponds to today’s full nodes. But it also could be group of servers operated by the same miner. Or it could be a group of subnodes operated by people who trust each other. Or it could be a group of subnodes that found together similar to today’s mining pools. For groups of random nodes from the Internet, there obviously needs some mechanism to enforce correct behavior. The most simple one would be to expel subnodes that did not process a transaction correctly, which fortunately can easily be detected once a block created by that group gets declined by the other groups (other groups could even provide a proof for the wrong-doing). How these groups are formed and organized exactly is not important at this stage (proper processing of cross-shard transactions is somewhat hairy, but feasible with a well-defined ordering of transactions and efficient collaboration within the group). What is important is that there exists an incentive to behave well as a group and that there is a large number of such groups so they stand in competition with each other. Generally, having diversity in the way groups are formed (manually or automatically) makes the system as a whole more robust (for example, it makes it harder to infiltrate every group with a node that handles the same subset of data, which is the equivalent of taking over a whole shard in Vitalik's model). With this boring variant, one could already scale up one or even two orders of magnitude.

*Block creation, bold variant*: what would happen if subnodes worked on their own or if a group does not cover the whole state? In that case, they could still craft blocks consisting of transactions that operate on state they know, but they would not be able to fully verify previous blocks. So maybe it is time to separate the creation of new blocks from the verification of old blocks. Today, miners get rewarded for doing both at the same time. Here, I propose to split the rewards for block creation and block verification, and thus to have creating and verifying subnodes. So the creating subnode would just proceed and attach freshly crafted block to the blockchain when it is his turn to do so according to the proof-of-work or proof-of-stake mechanism. However, he risks losing his reward if it turns out that he built on top of an invalid chain. And if there are thousands of verifying subnodes that verify randomly chosen transactions (or some randomly chosen subset of the state), the chances are high that one of them will find out eventuall (maybe they coordinate in pools so not every node verifies the same transactions). If a verifying subnode finds an invalid block, the proof for the invalidity is created and incorporated into a new block at the same height as the invalid block. Ideally, the creator of the invalid block is punished, which would be feasible with Casper-style proof of stake, and the subnode that found the error rewarded. Obviously, subnodes can engage in both if they want, creating and verifying blocks. Also, subnodes could still form groups in order to advance a larger subset of the state in each block, but these groups do not necessarily need to cover the full state. What is still missing in the bold variant is ensuring data availability, which I implicitly assumed to be solved. In the boring variant with the complete groups, one can postulate that the group as a whole has the power to download and verfiy whole blocks and thus implicitely solve data availability the same way it is solved today, namely to refuse to build on top of a block whose relevant data is not know. In the bold variant, we need a new mechanism to ensure data availability. But appart from that, I think it could actually hold water and represent a more simple and more versatile approach to scaling up to tens of thousands of transactions per second.

*Data availability*: This is basically the missing piece of the puzzle - and I am honestly not sure how it is ideally solved, but I will provide an idea. The important part is that if there is an efficient solution, then the above "bold variant" should work. In simple systems, nodes refuse to create blocks without knowing everything about the previous block (unless they do risky "SPV mining"). With blocks that are too large for individual nodes and even for organized groups of nodes to process, this simple mechanism does not work any more by definition, as a single node cannot hold all the data. So instead of starting with the creation of the next block once a miner has all data, we need to create a situation in which the optimal behavior is to start with the creation of the next block onces the miner is confident that all of the previous block's data is widely available. I leave it open for now how exactly that confidence is gained (there are various options) and focus on creating the right incentives. Assuming that someone in the network will detect unavailable data quickly, that unavailability can be signaled to the network. Every node that fails to fetch that piece of data discards the block with the missing data and starts mining a sibling instead. That creates a situation in which withholding data on purpose comes at the risk of having ones own block orphaned, and in which it is risky to mine on top of a block whose data is of questionable availability. Without doing the math, I think this might work, although not as well as the strict approach, where miners wait for having all the data themselves.

*Conclusion*: The advantage of this approach is that it provides a simple and robust path to scaling, while avoiding the synchronization headaches associated with cross-shard transactions. Agreeing on a “cross-shard” transaction within a small group of nodes is much easier than across large distributed shards. If the price of cross-contract calls in a transaction are well-aligned with the cost of collaboratively processing such transactions in a group of subnodes, programmers can live in a nice world without being exposed to the pain of asynchronous calls and worries about atomicity across shards. If you think I made a mistake or have any other comments, I'd love to hear your feedback on <a href="https://www.reddit.com/r/ethereum/">the Ethereum reddit</a>.
