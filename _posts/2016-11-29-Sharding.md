---
layout: post
title: Comment on Sharding in Ethereum
description: An alternate approach to sharding in Ethereum
---
UNDER CONSTRUCTION


<a href="https://github.com/ethereum/wiki/wiki/Sharding-FAQ">Vitalik Buterin's FAQ</a> on sharding in Ethereum has inspired me to come up with a more simple, robust, and versatile alternative to sharding. I start by slicing the network horizontally instead of vertically. Instead of creating groups of nodes that are responsible for a subset of the state (shards), I propose to create groups of nodes that are responsible for the full state each. I.e. instead of having 50 shards with 100 nodes each, there would be 100 groups consisting of 50 subnodes each, with each group holding the full state. I call this the *boring variant*. It already allows to scale the network by an order of magnitude or two, but the real magic starts in the *bold variant* that allows these groups to be incomplete and subnodes to mine on their own. Chances are high that I made some mistakes in my thinking, but I would love to find out where they are, so I invite you to comment this approach on <a href="https://www.reddit.com/r/ethereum/">the Ethereum reddit</a>.

**Subnodes**

One of the great advantages of Ethereum in comparison to other cryptocurrencies is that the state is encoded in a <a href="https://blog.ethereum.org/2015/11/15/merkling-in-ethereum/">Merkle tree</a>, and its current root present in every block. This allows to create compact proofs about the current state. In comparison, it is not possible to prove that a given output is unspent in Bitcoin without scanning the whole transaction history since the creation of that output. This valuable property of Ethereum allows the creation of subnodes that are more powerful than normal SPV nodes as they are able to craft valid blocks with valid transactions in them. In contrast to full nodes, subnodes are only concerned with a subset of the state, and only download and validate transactions that are relevant to that subset. Whoever runs a subnode is free to specify what subset of the state he is interested in. By default, this can be a random subset, but it might also make sense for a specific users to track the state that is relevant to all the contracts he is involved in. This stands in contrast to Vitalik’s proposal, where nodes are exogenously assigned to a subset of the state (shard). By running a subnode, a user would be able to monitor all the contracts relevant to him and even prove if something went wrong, i.e. if an invalid state transition was included in the block chain, he could provide the relevant transaction together with the Merkle-verified data before and after the transaction to prove to anyone that the transaction was incorrectly processed. Such a subnode could craft valid blocks that contain valid transactions, at least as long as these transactions only concern the state the node is tracking. This could even be expanded to simple "cross-shard" transactions if the node fetches the relevant data for those transaction from other nodes at O(log n) overhead.

**Block creation, boring variant**

In order to reliably validate old blocks and forge new blocks of transactions, subnodes have an incentive to form groups with other subnodes. Ideally, each group is large enough to cover the full state. Ideally, they also have some “mining power” among themselves, such that they can create new blocks. In the simplest case, such a group of nodes is actually just one supercomputer operated by a powerful miner and corresponds to today’s full nodes. But it also could be group of servers operated by the same miner. Or it could be a group of subnodes operated by people who trust each other. Or it could be a group of subnodes that found together similar to today’s mining pools. For groups of random nodes from the Internet, there obviously needs some mechanism to enforce correct behavior. The most simple one would be to expel subnodes that did not process a transaction correctly, which fortunately can easily be detected once a block created by that group gets declined by the other groups (other groups could even provide a proof for the wrong-doing). How these groups are formed and organized exactly is not important at this stage (proper processing of cross-shard transactions is somewhat hairy, but feasible with a well-defined ordering of transactions and efficient collaboration within the group). What is important is that there exists an incentive to behave well as a group and that there is a large number of such groups so they stand in competition with each other. Generally, having diversity in the way groups are formed (manually or automatically) makes the system as a whole more robust (for example, it makes it harder to infiltrate every group with a node that handles the same subset of data, which is the equivalent of taking over a whole shard in Vitalik's model). With this boring variant, one could already scale up one or even two orders of magnitude. The problem of scaling is reduced to the problem of making a group of subnodes behave like one of today's full nodes.

**Block creation, bold variant**

What would happen if subnodes worked on their own or if a group does not cover the whole state? In that case, they could still craft blocks consisting of transactions that operate on state they know. And in order to reap the maximal block reward, subnodes that operate on distinct subsets still have an incentive to collaborate in order to create larger blocks with a higher fee income, but they do not need to cover the whole state. However, unlike before, they would not be able anymore to completely verify previous blocks. They would depend on being informed by others about problems in the previous block that fall outside their domain. Assuming that each transaction of a block is verified by at least one honest subnode, invalid transactions are detected quickly and the proof for their invalidity can easily be passed around the network. A little more subtle is the case of missing data, as it is impossible to prove that a given piece of data was unavailable at some point in time (the data availability problem). In simpler systems, nodes refuse to create blocks without knowing everything about the previous block (unless they do risky "SPV mining"). With blocks that are too large for individual nodes and even for organized groups of nodes to process, this simple mechanism does not work any more. So instead of starting with the creation of the next block once a miner has all data, we need to create a situation in which the optimal behavior is to start with the creation of the next block onces the miner is confident that all of the previous block's data is widely available. Assuming that someone in the network will detect unavailable data quickly, that unavailability can be signaled to the network. Every node that fails to fetch that piece of data discards the block with the missing data and starts mining a sibling instead. That creates a situation in which withholding data on purpose comes at the risk of having ones own block orphaned, and in which it is risky to mine on top of a block whose data is of questionable availability. Without doing the math, I think this might work, although not as well as the strict approach, where miners wait for having all the data themselves.

**Conclusion**

The advantage of this approach is that it provides a simple and robust path to scaling, while avoiding the synchronization headaches associated with cross-shard transactions. Agreeing on a “cross-shard” transaction within a small group of nodes is much easier than across large distributed shards. If the price of cross-contract calls in a transaction are well-aligned with the cost of collaboratively processing such transactions in a group of subnodes, programmers can live in a nice world without being exposed to the pain of asynchronous calls and worries about atomicity across shards. A potential problem might be that blocks crafted by incomplete groups of subnotes will only advance that part of the state, increasing the number of blocks one has to wait at average for a transaction to be included. Another blind spot of this approach is that I left the organisation of the groups as an exercise to the reader, although it is non-trivial. If you see additional problems or have any other comments, I'd love to hear your feedback on <a href="https://www.reddit.com/r/ethereum/">the Ethereum reddit</a>.
